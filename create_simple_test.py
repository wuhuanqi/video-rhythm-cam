#!/usr/bin/env python3
"""
åˆ›å»ºç®€å•çš„æµ‹è¯•è§†é¢‘æ•°æ®
"""

import numpy as np
import soundfile as sf
from moviepy import VideoClip, AudioFileClip
import os

print("ğŸ¬ åˆ›å»ºæµ‹è¯•è§†é¢‘æ•°æ®...")

# åˆ›å»ºä¸´æ—¶ç›®å½•
os.makedirs('test_data', exist_ok=True)

# 1. åˆ›å»ºæµ‹è¯•éŸ³é¢‘ï¼ˆå¸¦èŠ‚å¥çš„éŸ³ä¹ï¼‰
sr = 22050
duration = 10.0  # 10ç§’
t = np.linspace(0, duration, int(sr * duration))

# åˆ›å»ºä¸€ä¸ªæœ‰èŠ‚å¥çš„éŸ³é¢‘ï¼ˆæ¯ç§’ä¸€ä¸ªèŠ‚æ‹ï¼‰
audio = np.zeros_like(t)
bpm = 60  # æ¯åˆ†é’Ÿ60æ‹
beat_interval = 60 / bpm  # æ¯æ‹çš„æ—¶é—´é—´éš”

for i in range(int(duration / beat_interval)):
    beat_time = i * beat_interval
    beat_idx = int(beat_time * sr)
    # åœ¨æ¯ä¸ªèŠ‚æ‹å¤„æ·»åŠ ä¸€ä¸ªçŸ­ä¿ƒçš„éŸ³è°ƒ
    if beat_idx < len(t):
        beat_duration = 0.1  # èŠ‚æ‹æŒç»­0.1ç§’
        beat_end_idx = min(beat_idx + int(beat_duration * sr), len(t))
        # æ·»åŠ 440Hzçš„æ­£å¼¦æ³¢
        audio[beat_idx:beat_end_idx] += np.sin(2 * np.pi * 440 * t[beat_idx:beat_end_idx]) * 0.5

# å½’ä¸€åŒ–
audio = audio / np.max(np.abs(audio)) * 0.8

# ä¿å­˜éŸ³é¢‘
sf.write('test_data/audio_with_beats.wav', audio, sr)
print(f"âœ… åˆ›å»ºéŸ³é¢‘: test_data/audio_with_beats.wav ({duration}ç§’, {bpm} BPM)")

# 2. åˆ›å»ºæµ‹è¯•è§†é¢‘1ï¼ˆèˆè¹ˆè§†é¢‘ï¼‰
print("\nğŸ“¹ åˆ›å»ºæµ‹è¯•è§†é¢‘1ï¼ˆèˆè¹ˆè§†é¢‘ï¼‰...")

def make_frame1(t):
    # æ ¹æ®æ—¶é—´è®¡ç®—é¢œè‰²ï¼ˆæ¨¡æ‹Ÿèˆè¹ˆåŠ¨ä½œï¼‰
    beat_idx = int(t / beat_interval)
    colors = [
        [255, 100, 100],  # çº¢è‰²
        [100, 255, 100],  # ç»¿è‰²
        [100, 100, 255],  # è“è‰²
        [255, 255, 100],  # é»„è‰²
        [255, 100, 255],  # ç´«è‰²
    ]
    color = colors[beat_idx % len(colors)]
    frame = np.zeros((480, 640, 3), dtype=np.uint8)
    frame[:, :] = color
    return frame

video1 = VideoClip(make_frame1, duration=duration)
video1.fps = 30

# æ·»åŠ éŸ³é¢‘
audio_clip = AudioFileClip('test_data/audio_with_beats.wav')
video1 = video1.with_audio(audio_clip)

# ä¿å­˜è§†é¢‘
video1.write_videofile('test_data/dance_video.mp4', codec='libx264', audio_codec='aac', logger=None)
print(f"âœ… åˆ›å»ºè§†é¢‘1: test_data/dance_video.mp4")

video1.close()
audio_clip.close()

# 3. åˆ›å»ºæµ‹è¯•è§†é¢‘2ï¼ˆå‚è€ƒè§†é¢‘ - å¸¦éŸ³é¢‘åç§»ï¼‰
print("\nğŸ“¹ åˆ›å»ºæµ‹è¯•è§†é¢‘2ï¼ˆå‚è€ƒè§†é¢‘ - éŸ³é¢‘å»¶è¿Ÿ2ç§’ï¼‰...")

def make_frame2(t):
    # ä¸åŒçš„è§†è§‰æ•ˆæœï¼ˆæ¸å˜åœ†åœˆï¼‰
    frame = np.zeros((480, 640, 3), dtype=np.uint8)
    center_x, center_y = 320, 240
    radius = int(50 + 30 * np.sin(2 * np.pi * t))
    y, x = np.ogrid[:480, :640]
    mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2
    frame[mask] = [100, 200, 255]  # è“è‰²åœ†åœˆ
    return frame

video2 = VideoClip(make_frame2, duration=duration)
video2.fps = 30

# åˆ›å»ºä¸€ä¸ªå¸¦2ç§’å»¶è¿Ÿçš„éŸ³é¢‘ï¼ˆå‰é¢åŠ 2ç§’é™éŸ³ï¼‰
silence_samples = int(2.0 * sr)
audio_with_delay = np.concatenate([np.zeros(silence_samples), audio])

# ä¿å­˜å»¶è¿Ÿåçš„éŸ³é¢‘
sf.write('test_data/audio_delayed.wav', audio_with_delay[:int(sr * duration)], sr)

# æ·»åŠ å»¶è¿Ÿçš„éŸ³é¢‘
audio_clip2 = AudioFileClip('test_data/audio_delayed.wav')
video2 = video2.with_audio(audio_clip2)

# ä¿å­˜è§†é¢‘
video2.write_videofile('test_data/reference_video.mp4', codec='libx264', audio_codec='aac', logger=None)
print(f"âœ… åˆ›å»ºè§†é¢‘2: test_data/reference_video.mp4 (éŸ³é¢‘å»¶è¿Ÿ2ç§’)")

video2.close()
audio_clip2.close()

print("\nâœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆï¼")
print("ğŸ“ æ–‡ä»¶ä½ç½®:")
print("   - èˆè¹ˆè§†é¢‘: test_data/dance_video.mp4 (éŸ³é¢‘æ— å»¶è¿Ÿ)")
print("   - å‚è€ƒè§†é¢‘: test_data/reference_video.mp4 (éŸ³é¢‘å»¶è¿Ÿ2ç§’)")
print("   - éŸ³é¢‘æ–‡ä»¶: test_data/audio_with_beats.wav")
print("\nğŸ’¡ è¿™ä¸¤ä¸ªè§†é¢‘çš„éŸ³é¢‘ç›¸å·®2ç§’ï¼Œå¯ä»¥ç”¨æ¥æµ‹è¯•éŸ³é¢‘å¯¹é½åŠŸèƒ½")
