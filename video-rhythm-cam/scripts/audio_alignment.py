#!/usr/bin/env python3
"""
éŸ³é¢‘å¯¹é½æ¨¡å—
å°†ä¸¤ä¸ªéŸ³é¢‘é€šè¿‡æ—¶é—´åç§»è¿›è¡ŒèŠ‚å¥å¯¹é½
ç”¨äºæ›¿æ¢èˆè¹ˆè§†é¢‘çš„éŸ³é¢‘ä¸ºé«˜è´¨é‡éŸ³é¢‘
"""

import os
import tempfile
import numpy as np
import librosa
import soundfile as sf
from typing import Tuple
from scipy import signal


def extract_audio_from_video(video_path: str, output_audio: str) -> bool:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    try:
        from moviepy import VideoFileClip

        print(f"ğŸ“¤ æ­£åœ¨ä»è§†é¢‘æå–éŸ³é¢‘: {video_path}")
        video = VideoFileClip(video_path)
        audio = video.audio

        if audio is None:
            print("âŒ è§†é¢‘ä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“")
            return False

        audio.write_audiofile(output_audio, logger=None)
        audio.close()
        video.close()

        print(f"âœ… éŸ³é¢‘å·²æå–: {output_audio}")
        return True
    except Exception as e:
        print(f"âŒ æå–éŸ³é¢‘å¤±è´¥: {e}")
        return False


def find_best_offset(audio1_path: str, audio2_path: str, max_offset: float = 5.0) -> float:
    """
    æ‰¾åˆ°ä¸¤ä¸ªéŸ³é¢‘ä¹‹é—´çš„æœ€ä½³æ—¶é—´åç§»é‡
    ä½¿ç”¨äº¤å‰ç›¸å…³ç®—æ³•

    Args:
        audio1_path: å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆé«˜è´¨é‡éŸ³é¢‘ï¼‰
        audio2_path: åŸå§‹éŸ³é¢‘è·¯å¾„ï¼ˆèˆè¹ˆè§†é¢‘çš„éŸ³é¢‘ï¼‰
        max_offset: æœ€å¤§åç§»é‡ï¼ˆç§’ï¼‰

    Returns:
        æœ€ä½³æ—¶é—´åç§»é‡ï¼ˆç§’ï¼‰ï¼Œæ­£æ•°è¡¨ç¤º audio1 éœ€è¦å‘åç§»åŠ¨
    """
    try:
        print("ğŸ” æ­£åœ¨è®¡ç®—æœ€ä½³æ—¶é—´åç§»é‡...")

        # åŠ è½½éŸ³é¢‘
        y1, sr1 = librosa.load(audio1_path, sr=22050)  # é™é‡‡æ ·ä»¥æé«˜é€Ÿåº¦
        y2, sr2 = librosa.load(audio2_path, sr=22050)

        # è®¡ç®—èŠ‚æ‹å¼ºåº¦ï¼ˆonset strengthï¼‰
        hop_length = 512
        onset_env1 = librosa.onset.onset_strength(y=y1, sr=sr1, hop_length=hop_length)
        onset_env2 = librosa.onset.onset_strength(y=y2, sr=sr1, hop_length=hop_length)

        # å½’ä¸€åŒ–
        onset_env1 = (onset_env1 - onset_env1.mean()) / (onset_env1.std() + 1e-8)
        onset_env2 = (onset_env2 - onset_env2.mean()) / (onset_env2.std() + 1e-8)

        # é™åˆ¶æœç´¢èŒƒå›´
        max_frames = int(max_offset * sr1 / hop_length)
        search_range = min(len(onset_env2), max_frames * 2)

        # ä½¿ç”¨äº¤å‰ç›¸å…³æ‰¾åˆ°æœ€ä½³åç§»
        correlation = signal.correlate(onset_env1, onset_env2[:search_range], mode='valid')

        # æ‰¾åˆ°æœ€å¤§ç›¸å…³æ€§çš„ä½ç½®
        max_corr_idx = np.argmax(correlation)

        # è½¬æ¢ä¸ºæ—¶é—´ï¼ˆç§’ï¼‰
        offset_frames = max_corr_idx - len(onset_env2[:search_range]) + 1
        offset_seconds = offset_frames * hop_length / sr1

        print(f"âœ… æœ€ä½³æ—¶é—´åç§»é‡: {offset_seconds:.3f} ç§’")

        return offset_seconds

    except Exception as e:
        print(f"âŒ è®¡ç®—åç§»é‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0.0


def apply_offset_to_audio(audio_path: str, offset: float, output_path: str) -> bool:
    """
    å¯¹éŸ³é¢‘åº”ç”¨æ—¶é—´åç§»

    Args:
        audio_path: è¾“å…¥éŸ³é¢‘è·¯å¾„
        offset: æ—¶é—´åç§»é‡ï¼ˆç§’ï¼‰ï¼Œæ­£æ•°è¡¨ç¤ºå‘åç§»åŠ¨ï¼ˆå‰é¢åŠ é™éŸ³ï¼‰
        output_path: è¾“å‡ºéŸ³é¢‘è·¯å¾„

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        print(f"ğŸ”§ æ­£åœ¨åº”ç”¨æ—¶é—´åç§»: {offset:.3f} ç§’")

        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path)
        audio_duration = len(y) / sr

        # è®¡ç®—åç§»çš„æ ·æœ¬æ•°
        offset_samples = int(offset * sr)

        # ç¡®ä¿ä¸ä¼šè£å‰ªæ‰å¤ªå¤šéŸ³é¢‘ï¼ˆä¿ç•™è‡³å°‘ 80% çš„åŸå§‹éŸ³é¢‘ï¼‰
        max_negative_offset = -int(len(y) * 0.8)
        if offset_samples < max_negative_offset:
            print(f"âš ï¸  è­¦å‘Š: åç§»é‡è¿‡å¤§ï¼Œè°ƒæ•´ä¸º {max_negative_offset / sr:.3f} ç§’")
            offset_samples = max_negative_offset

        if offset_samples > 0:
            # å‘åç§»åŠ¨ï¼šåœ¨å‰é¢æ·»åŠ é™éŸ³
            silence = np.zeros(offset_samples)
            y_offset = np.concatenate([silence, y])
        elif offset_samples < 0:
            # å‘å‰ç§»åŠ¨ï¼šåˆ é™¤å‰é¢çš„éƒ¨åˆ†
            y_offset = y[-offset_samples:]
        else:
            # æ²¡æœ‰åç§»
            y_offset = y

        # ä¿å­˜éŸ³é¢‘
        sf.write(output_path, y_offset, sr)

        print(f"âœ… åç§»åçš„éŸ³é¢‘å·²ä¿å­˜: {output_path}")
        return True

    except Exception as e:
        print(f"âŒ åº”ç”¨åç§»å¤±è´¥: {e}")
        return False


def align_and_replace_audio(
    dance_video_path: str,
    reference_video_path: str,
    output_video_path: str,
    max_offset: float = 5.0
) -> Tuple[bool, float]:
    """
    å¯¹é½ä¸¤ä¸ªè§†é¢‘çš„éŸ³é¢‘å¹¶æ›¿æ¢åˆ°èˆè¹ˆè§†é¢‘ä¸­

    Args:
        dance_video_path: åŸå§‹èˆè¹ˆè§†é¢‘è·¯å¾„
        reference_video_path: å‚è€ƒè§†é¢‘è·¯å¾„ï¼ˆåŒ…å«é«˜è´¨é‡éŸ³é¢‘ï¼‰
        output_video_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        max_offset: æœ€å¤§åç§»é‡ï¼ˆç§’ï¼‰

    Returns:
        (æ˜¯å¦æˆåŠŸ, å®é™…åç§»é‡)
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        # æå–éŸ³é¢‘
        reference_audio = os.path.join(tmpdir, "reference_audio.wav")
        dance_audio = os.path.join(tmpdir, "dance_audio.wav")

        print("\n" + "="*60)
        print("ğŸµ ç¬¬ä¸€æ­¥ï¼šæå–éŸ³é¢‘")
        print("="*60)

        if not extract_audio_from_video(reference_video_path, reference_audio):
            return False, 0.0

        if not extract_audio_from_video(dance_video_path, dance_audio):
            return False, 0.0

        print("\n" + "="*60)
        print("ğŸ¯ ç¬¬äºŒæ­¥ï¼šè®¡ç®—æ—¶é—´åç§»")
        print("="*60)

        # è®¡ç®—æœ€ä½³åç§»ï¼ˆå‚è€ƒéŸ³é¢‘éœ€è¦ç§»åŠ¨å¤šå°‘æ‰èƒ½å¯¹é½èˆè¹ˆéŸ³é¢‘ï¼‰
        offset = find_best_offset(reference_audio, dance_audio, max_offset)

        print("\n" + "="*60)
        print("ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šåº”ç”¨åç§»å¹¶åˆæˆè§†é¢‘")
        print("="*60)

        # åº”ç”¨åç§»åˆ°å‚è€ƒéŸ³é¢‘
        aligned_audio = os.path.join(tmpdir, "aligned_audio.wav")
        if not apply_offset_to_audio(reference_audio, offset, aligned_audio):
            return False, 0.0

        # ä½¿ç”¨ moviepy æ›¿æ¢éŸ³é¢‘
        try:
            from moviepy import VideoFileClip, AudioFileClip

            print(f"ğŸ¬ æ­£åœ¨åˆæˆè§†é¢‘...")

            # åŠ è½½è§†é¢‘å’ŒéŸ³é¢‘
            dance_video = VideoFileClip(dance_video_path)
            new_audio = AudioFileClip(aligned_audio)

            # è°ƒæ•´éŸ³é¢‘é•¿åº¦ä»¥åŒ¹é…è§†é¢‘
            if new_audio.duration > dance_video.duration:
                # éŸ³é¢‘æ¯”è§†é¢‘é•¿ï¼Œè£å‰ªéŸ³é¢‘
                new_audio = new_audio.subclip(0, dance_video.duration)

            # è£å‰ªè§†é¢‘é•¿åº¦ä»¥åŒ¹é…éŸ³é¢‘ï¼ˆå¦‚æœéŸ³é¢‘æ›´çŸ­ï¼‰
            if dance_video.duration > new_audio.duration:
                dance_video = dance_video.subclipped(0, new_audio.duration)

            # è®¾ç½®éŸ³é¢‘
            final_video = dance_video.with_audio(new_audio)

            # å†™å…¥è¾“å‡ºæ–‡ä»¶
            final_video.write_videofile(
                output_video_path,
                codec='libx264',
                audio_codec='aac',
                logger=None
            )

            # æ¸…ç†
            dance_video.close()
            new_audio.close()
            final_video.close()

            print(f"\nâœ… è§†é¢‘åˆæˆå®Œæˆ: {output_video_path}")
            print(f"ğŸ“Š éŸ³é¢‘åç§»é‡: {offset:.3f} ç§’")

            return True, offset

        except Exception as e:
            print(f"âŒ åˆæˆè§†é¢‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, 0.0


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description='å¯¹é½ä¸¤ä¸ªè§†é¢‘çš„éŸ³é¢‘å¹¶åˆæˆ'
    )
    parser.add_argument('dance_video', help='åŸå§‹èˆè¹ˆè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('reference_video', help='å‚è€ƒè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆé«˜è´¨é‡éŸ³é¢‘ï¼‰')
    parser.add_argument('-o', '--output', help='è¾“å‡ºè§†é¢‘è·¯å¾„')
    parser.add_argument('--max-offset', type=float, default=5.0,
                       help='æœ€å¤§åç§»é‡ï¼ˆç§’ï¼‰(é»˜è®¤: 5.0)')

    args = parser.parse_args()

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if args.output:
        output_path = args.output
    else:
        base, _ = os.path.splitext(args.dance_video)
        output_path = f"{base}_aligned.mp4"

    # å¯¹é½å¹¶åˆæˆ
    success, offset = align_and_replace_audio(
        args.dance_video,
        args.reference_video,
        output_path,
        args.max_offset
    )

    if success:
        print(f"\nğŸ‰ æˆåŠŸï¼åç§»é‡: {offset:.3f} ç§’")
    else:
        print("\nâŒ å¤±è´¥")

    exit(0 if success else 1)
