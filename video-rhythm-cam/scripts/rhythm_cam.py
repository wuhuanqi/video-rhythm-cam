#!/usr/bin/env python3
"""
è§†é¢‘èŠ‚å¥è¿é•œè„šæœ¬
ä¸ºèˆè¹ˆè§†é¢‘è‡ªåŠ¨æ·»åŠ è·ŸéšéŸ³ä¹èŠ‚å¥çš„ç¼©æ”¾æ•ˆæœ
"""

import os
import sys
import argparse
import tempfile
import numpy as np
from typing import List, Tuple


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    try:
        import moviepy
        import librosa
        import librosa.display
        import soundfile as sf
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
        print("\nè¯·å®‰è£…ä»¥ä¸‹ä¾èµ–:")
        print("  pip install moviepy librosa soundfile numpy")
        return False


def extract_audio(video_path: str, audio_path: str) -> bool:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    from moviepy import VideoFileClip

    try:
        print("ğŸ“¤ æ­£åœ¨æå–éŸ³é¢‘...")
        video = VideoFileClip(video_path)
        audio = video.audio

        if audio is None:
            print("âŒ è§†é¢‘ä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“")
            return False

        audio.write_audiofile(audio_path)
        audio.close()
        video.close()

        print(f"âœ… éŸ³é¢‘å·²æå–åˆ°: {audio_path}")
        return True
    except Exception as e:
        print(f"âŒ æå–éŸ³é¢‘å¤±è´¥: {e}")
        return False


def detect_beats_with_strength(audio_path: str, sensitivity: float = 0.5) -> Tuple[List[Tuple[float, float]], float]:
    """
    æ£€æµ‹éŸ³é¢‘ä¸­çš„èŠ‚æ‹ç‚¹ï¼Œå¹¶åŒºåˆ†é‡æ‹å’Œå¼±æ‹

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        sensitivity: èŠ‚æ‹æ£€æµ‹çµæ•åº¦ (0.0-1.0), è¶Šé«˜æ£€æµ‹åˆ°çš„èŠ‚æ‹è¶Šå¤š

    Returns:
        ((æ—¶é—´, å¼ºåº¦) åˆ—è¡¨, éŸ³é¢‘æ—¶é•¿)
    """
    import librosa
    import soundfile as sf

    try:
        print("ğŸµ æ­£åœ¨åˆ†æéŸ³ä¹èŠ‚å¥å’Œå¼ºåº¦...")

        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path)
        duration = len(y) / sr

        # æ£€æµ‹èŠ‚æ‹
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)

        # å°†å¸§è½¬æ¢ä¸ºæ—¶é—´(ç§’)
        beat_times = librosa.frames_to_time(beats, sr=sr)

        # è®¡ç®—èŠ‚æ‹å¼ºåº¦
        onset_env = librosa.onset.onset_strength(y=y, sr=sr)
        beat_frames = librosa.time_to_frames(beat_times, sr=sr)
        beat_strength = onset_env[beat_frames]

        # å½’ä¸€åŒ–å¼ºåº¦åˆ° 0-1 èŒƒå›´
        if len(beat_strength) > 0:
            beat_strength_normalized = (beat_strength - beat_strength.min()) / (beat_strength.max() - beat_strength.min() + 1e-8)
        else:
            beat_strength_normalized = beat_strength

        # æ ¹æ®çµæ•åº¦è¿‡æ»¤èŠ‚æ‹
        if sensitivity < 1.0:
            threshold = np.percentile(beat_strength_normalized, (1 - sensitivity) * 100)
            mask = beat_strength_normalized >= threshold
            beat_times = beat_times[mask]
            beat_strength_normalized = beat_strength_normalized[mask]

        # ç»„åˆæ—¶é—´å’Œå¼ºåº¦
        beats_with_strength = list(zip(beat_times, beat_strength_normalized))

        # ç»Ÿè®¡é‡æ‹æ•°é‡
        strong_beats = sum(1 for _, strength in beats_with_strength if strength > 0.6)
        print(f"âœ… æ£€æµ‹åˆ° {len(beats_with_strength)} ä¸ªèŠ‚æ‹ç‚¹ (BPM: {float(tempo):.1f})")
        print(f"   å…¶ä¸­é‡æ‹: {strong_beats} ä¸ª")

        return beats_with_strength, duration

    except Exception as e:
        print(f"âŒ èŠ‚æ‹æ£€æµ‹å¤±è´¥: {e}")
        return [], 0.0


def create_zoom_clip(video_path: str, beat_times: List[float],
                     zoom_min: float = 1.0, zoom_max: float = 1.3,
                     zoom_duration: float = 0.2) -> str:
    """
    åˆ›å»ºå¸¦èŠ‚å¥ç¼©æ”¾æ•ˆæœçš„è§†é¢‘

    Args:
        video_path: åŸè§†é¢‘è·¯å¾„
        beat_times: èŠ‚æ‹æ—¶é—´ç‚¹åˆ—è¡¨
        zoom_min: æœ€å°ç¼©æ”¾æ¯”ä¾‹
        zoom_max: æœ€å¤§ç¼©æ”¾æ¯”ä¾‹
        zoom_duration: æ¯æ¬¡ç¼©æ”¾çš„æŒç»­æ—¶é—´(ç§’)

    Returns:
        è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    from moviepy import VideoFileClip

    try:
        print("ğŸ¬ æ­£åœ¨åº”ç”¨è¿é•œæ•ˆæœ...")

        video = VideoFileClip(video_path)
        w, h = video.size

        # ä¸ºæ¯ä¸ªèŠ‚æ‹åˆ›å»ºç¼©æ”¾å…³é”®å¸§
        # ä½¿ç”¨ç®€å•çš„ç¼©æ”¾ç­–ç•¥: åœ¨èŠ‚æ‹å¤„æ”¾å¤§,ç„¶åç¼©å°
        def zoom_effect(get_frame, t):
            # æ‰¾åˆ°æœ€è¿‘çš„èŠ‚æ‹
            if not beat_times:
                return get_frame(t)

            # æ‰¾åˆ°æœ€è¿‘çš„èŠ‚æ‹æ—¶é—´
            beat_deltas = [abs(t - beat) for beat in beat_times]
            nearest_beat_dist = min(beat_deltas)

            # å¦‚æœæ¥è¿‘èŠ‚æ‹,åº”ç”¨ç¼©æ”¾
            if nearest_beat_dist < zoom_duration:
                # è®¡ç®—ç¼©æ”¾å› å­: èŠ‚æ‹å¤„æœ€å¤§,ç„¶åè¡°å‡
                progress = nearest_beat_dist / zoom_duration
                zoom_factor = zoom_max - (zoom_max - zoom_min) * progress
            else:
                zoom_factor = zoom_min

            # åº”ç”¨ç¼©æ”¾
            frame = get_frame(t)
            # è®¡ç®—ç¼©æ”¾åçš„å°ºå¯¸
            new_w, new_h = int(w / zoom_factor), int(h / zoom_factor)

            # å±…ä¸­è£å‰ª
            x1 = (w - new_w) // 2
            y1 = (h - new_h) // 2
            x2 = x1 + new_w
            y2 = y1 + new_h

            # è£å‰ªå¹¶ç¼©æ”¾å›åŸå°ºå¯¸
            from cv2 import resize
            cropped = frame[y1:y2, x1:x2]
            if cropped.size == 0:
                return frame
            return resize(cropped, (w, h))

        # åº”ç”¨æ•ˆæœ
        result = video.fl(zoom_effect)

        print(f"âœ… è¿é•œæ•ˆæœå·²åº”ç”¨")
        return result

    except Exception as e:
        print(f"âŒ åº”ç”¨æ•ˆæœå¤±è´¥: {e}")
        return None


def process_video(video_path: str, output_path: str,
                  sensitivity: float = 0.5,
                  zoom_min: float = 1.0,
                  zoom_max: float = 1.3,
                  zoom_duration: float = 0.2) -> bool:
    """
    å¤„ç†è§†é¢‘çš„ä¸»å‡½æ•°

    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        sensitivity: èŠ‚æ‹æ£€æµ‹çµæ•åº¦ (0.0-1.0)
        zoom_min: æœ€å°ç¼©æ”¾æ¯”ä¾‹
        zoom_max: æœ€å¤§ç¼©æ”¾æ¯”ä¾‹
        zoom_duration: ç¼©æ”¾æŒç»­æ—¶é—´(ç§’)

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    from moviepy import VideoFileClip

    # éªŒè¯è¾“å…¥
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return False

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as tmpdir:
        audio_path = os.path.join(tmpdir, "audio.wav")

        # æ­¥éª¤1: æå–éŸ³é¢‘
        if not extract_audio(video_path, audio_path):
            return False

        # æ­¥éª¤2: æ£€æµ‹èŠ‚æ‹ï¼ˆå¸¦å¼ºåº¦ï¼‰
        beats_with_strength, duration = detect_beats_with_strength(audio_path, sensitivity)
        if not beats_with_strength:
            print("âŒ æœªæ£€æµ‹åˆ°èŠ‚æ‹")
            return False

        # æ­¥éª¤3: åº”ç”¨ç¼©æ”¾æ•ˆæœ
        try:
            print("ğŸ¬ æ­£åœ¨æ¸²æŸ“æœ€ç»ˆè§†é¢‘...")

            video = VideoFileClip(video_path)
            original_audio = video.audio
            w, h = video.size
            fps = video.fps

            # ä½¿ç”¨ cv2 è¿›è¡Œæ›´é«˜æ•ˆçš„å¤„ç†
            try:
                import cv2
            except ImportError:
                print("âŒ éœ€è¦å®‰è£… cv2 (opencv-python)")
                print("  pip install opencv-python")
                return False

            # åˆ›å»ºä¸´æ—¶æ— éŸ³é¢‘è§†é¢‘æ–‡ä»¶
            temp_video_no_audio = os.path.join(tmpdir, "temp_no_audio.mp4")

            # ä½¿ç”¨ H.264 ç¼–ç å™¨ï¼Œè®¾ç½®é«˜è´¨é‡å‚æ•°
            fourcc = cv2.VideoWriter_fourcc(*'avc1')
            # æé«˜ç¼–ç è´¨é‡
            out = cv2.VideoWriter(temp_video_no_audio, fourcc, fps, (w, h),
                                 [cv2.VIDEOWRITER_PROP_QUALITY, 95])

            # é€å¸§å¤„ç†
            total_frames = int(duration * fps)
            for i in range(total_frames):
                t = i / fps

                # è·å–åŸå§‹å¸§ï¼ˆä¿æŒåŸå§‹è‰²å½©ç©ºé—´ï¼‰
                frame = video.get_frame(t)

                # è®¡ç®—ç¼©æ”¾å› å­ - åŸºäºèŠ‚æ‹å¼ºåº¦
                if beats_with_strength:
                    # æ‰¾åˆ°æœ€è¿‘çš„èŠ‚æ‹åŠå…¶å¼ºåº¦
                    min_dist = float('inf')
                    nearest_strength = 0.0

                    for beat_time, beat_strength in beats_with_strength:
                        dist = abs(t - beat_time)
                        if dist < min_dist:
                            min_dist = dist
                            nearest_strength = beat_strength

                    if min_dist < zoom_duration:
                        # æ ¹æ®å¼ºåº¦åŠ¨æ€è°ƒæ•´ç¼©æ”¾å¹…åº¦
                        # é‡æ‹ï¼ˆå¼ºåº¦>0.6ï¼‰: zoom_min åˆ° zoom_max
                        # å¼±æ‹ï¼ˆå¼ºåº¦<=0.6ï¼‰: zoom_min åˆ° (zoom_min + zoom_max) / 2
                        if nearest_strength > 0.6:
                            # é‡æ‹ - æ›´å¤§çš„ç¼©æ”¾å¹…åº¦
                            max_zoom = zoom_max
                        else:
                            # å¼±æ‹ - è¾ƒå°çš„ç¼©æ”¾å¹…åº¦
                            max_zoom = zoom_min + (zoom_max - zoom_min) * 0.6

                        progress = min_dist / zoom_duration
                        zoom_factor = max_zoom - (max_zoom - zoom_min) * progress
                    else:
                        zoom_factor = zoom_min
                else:
                    zoom_factor = zoom_min

                # åº”ç”¨ç¼©æ”¾
                if zoom_factor > zoom_min * 1.01:  # ç¨å¾®å¤§äºminæ‰åº”ç”¨ç¼©æ”¾
                    new_w, new_h = int(w / zoom_factor), int(h / zoom_factor)
                    x1 = (w - new_w) // 2
                    y1 = (h - new_h) // 2
                    x2 = x1 + new_w
                    y2 = y1 + new_h

                    # ä¿æŒè‰²å½©ç©ºé—´ï¼šRGB -> BGR (OpenCVæ ¼å¼)
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    cropped = frame_bgr[y1:y2, x1:x2]
                    # ä½¿ç”¨ LANCZOS æ’å€¼è·å¾—æ›´å¥½çš„ç¼©æ”¾è´¨é‡
                    frame = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)
                else:
                    # ä¿æŒåŸè‰²å½©
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

                out.write(frame)

                # æ˜¾ç¤ºè¿›åº¦
                if i % 30 == 0:
                    print(f"   è¿›åº¦: {i/total_frames*100:.1f}%")

            out.release()

            # å¦‚æœæœ‰éŸ³é¢‘ï¼Œå…ˆä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_audio_path = None
            if original_audio is not None:
                print("ğŸ”Š æ­£åœ¨ä¿å­˜éŸ³é¢‘...")
                temp_audio_path = os.path.join(tmpdir, "temp_audio.wav")
                original_audio.write_audiofile(temp_audio_path)
                # å…³é—­åŸå§‹éŸ³é¢‘å’Œè§†é¢‘ä»¥é‡Šæ”¾èµ„æº
                original_audio.close()
                original_audio = None
            video.close()

            # æ·»åŠ éŸ³é¢‘åˆ°è§†é¢‘
            print("ğŸ”Š æ­£åœ¨åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘...")
            video_processed = VideoFileClip(temp_video_no_audio)

            if temp_audio_path is not None:
                from moviepy import AudioFileClip
                audio_final = AudioFileClip(temp_audio_path)
                final_video = video_processed.with_audio(audio_final)
            else:
                final_video = video_processed

            # ä½¿ç”¨é«˜è´¨é‡å‚æ•°è¾“å‡º
            final_video.write_videofile(
                output_path,
                codec='libx264',
                audio_codec='aac',
                bitrate='12000k',  # æ›´é«˜æ¯”ç‰¹ç‡ä¿è¯è´¨é‡
                preset='slow',  # ä½¿ç”¨æ…¢é€Ÿé¢„è®¾è·å¾—æ›´å¥½çš„å‹ç¼©
                ffmpeg_params=['-crf', '18',  # CRF 18 ä¸ºé«˜è´¨é‡
                               '-pix_fmt', 'yuv420p',  # æ ‡å‡†åƒç´ æ ¼å¼
                               '-colorspace', 'bt709',  # ä¿æŒè‰²å½©ç©ºé—´
                               '-movflags', '+faststart']  # ä¼˜åŒ–ç½‘ç»œæ’­æ”¾
            )

            video_processed.close()
            if temp_audio_path is not None:
                audio_final.close()
            final_video.close()

            print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
            return True

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    parser = argparse.ArgumentParser(
        description='ä¸ºèˆè¹ˆè§†é¢‘æ·»åŠ è·ŸéšéŸ³ä¹èŠ‚å¥çš„ç¼©æ”¾è¿é•œæ•ˆæœ'
    )
    parser.add_argument('video', help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºè§†é¢‘è·¯å¾„ (é»˜è®¤: output_rhythm.mp4)')
    parser.add_argument('-s', '--sensitivity', type=float, default=0.5,
                       help='èŠ‚æ‹æ£€æµ‹çµæ•åº¦ (0.0-1.0, é»˜è®¤: 0.5)')
    parser.add_argument('--zoom-min', type=float, default=1.0,
                       help='æœ€å°ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤: 1.0)')
    parser.add_argument('--zoom-max', type=float, default=1.3,
                       help='æœ€å¤§ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤: 1.3)')
    parser.add_argument('--zoom-duration', type=float, default=0.2,
                       help='ç¼©æ”¾æŒç»­æ—¶é—´(ç§’) (é»˜è®¤: 0.2)')

    args = parser.parse_args()

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if args.output:
        output_path = args.output
    else:
        base, _ = os.path.splitext(args.video)
        output_path = f"{base}_rhythm.mp4"

    # å¤„ç†è§†é¢‘
    success = process_video(
        args.video,
        output_path,
        sensitivity=args.sensitivity,
        zoom_min=args.zoom_min,
        zoom_max=args.zoom_max,
        zoom_duration=args.zoom_duration
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
