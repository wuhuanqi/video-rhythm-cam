#!/usr/bin/env python3
"""
è§†é¢‘èŠ‚å¥è¿é•œè„šæœ¬
ä¸ºèˆè¹ˆè§†é¢‘è‡ªåŠ¨æ·»åŠ è·ŸéšéŸ³ä¹èŠ‚å¥çš„ç¼©æ”¾æ•ˆæœ
"""

import os
import sys
import argparse
import tempfile
import numpy as np
from typing import List, Tuple


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    try:
        import moviepy
        import librosa
        import librosa.display
        import soundfile as sf
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
        print("\nè¯·å®‰è£…ä»¥ä¸‹ä¾èµ–:")
        print("  pip install moviepy librosa soundfile numpy")
        return False


def extract_audio(video_path: str, audio_path: str) -> bool:
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    from moviepy import VideoFileClip

    try:
        print("ğŸ“¤ æ­£åœ¨æå–éŸ³é¢‘...")
        video = VideoFileClip(video_path)
        audio = video.audio

        if audio is None:
            print("âŒ è§†é¢‘ä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“")
            return False

        audio.write_audiofile(audio_path)
        audio.close()
        video.close()

        print(f"âœ… éŸ³é¢‘å·²æå–åˆ°: {audio_path}")
        return True
    except Exception as e:
        print(f"âŒ æå–éŸ³é¢‘å¤±è´¥: {e}")
        return False


def detect_beats(audio_path: str, sensitivity: float = 0.5) -> Tuple[List[float], float]:
    """
    æ£€æµ‹éŸ³é¢‘ä¸­çš„èŠ‚æ‹ç‚¹

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        sensitivity: èŠ‚æ‹æ£€æµ‹çµæ•åº¦ (0.0-1.0), è¶Šé«˜æ£€æµ‹åˆ°çš„èŠ‚æ‹è¶Šå¤š

    Returns:
        (èŠ‚æ‹æ—¶é—´åˆ—è¡¨, éŸ³é¢‘æ—¶é•¿)
    """
    import librosa
    import soundfile as sf

    try:
        print("ğŸµ æ­£åœ¨åˆ†æéŸ³ä¹èŠ‚å¥...")

        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path)
        duration = len(y) / sr

        # æ£€æµ‹èŠ‚æ‹
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)

        # å°†å¸§è½¬æ¢ä¸ºæ—¶é—´(ç§’)
        beat_times = librosa.frames_to_time(beats, sr=sr)

        # æ ¹æ®çµæ•åº¦è¿‡æ»¤èŠ‚æ‹
        if sensitivity < 1.0:
            # è®¡ç®—èŠ‚æ‹å¼ºåº¦
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            beat_strength = onset_env[librosa.time_to_frames(beat_times, sr=sr)]

            # åªä¿ç•™å¼ºåº¦é«˜äºé˜ˆå€¼çš„èŠ‚æ‹
            threshold = np.percentile(beat_strength, (1 - sensitivity) * 100)
            mask = beat_strength >= threshold
            beat_times = beat_times[mask]

        print(f"âœ… æ£€æµ‹åˆ° {len(beat_times)} ä¸ªèŠ‚æ‹ç‚¹ (BPM: {float(tempo):.1f})")
        return beat_times.tolist(), duration

    except Exception as e:
        print(f"âŒ èŠ‚æ‹æ£€æµ‹å¤±è´¥: {e}")
        return [], 0.0


def create_zoom_clip(video_path: str, beat_times: List[float],
                     zoom_min: float = 1.0, zoom_max: float = 1.3,
                     zoom_duration: float = 0.2) -> str:
    """
    åˆ›å»ºå¸¦èŠ‚å¥ç¼©æ”¾æ•ˆæœçš„è§†é¢‘

    Args:
        video_path: åŸè§†é¢‘è·¯å¾„
        beat_times: èŠ‚æ‹æ—¶é—´ç‚¹åˆ—è¡¨
        zoom_min: æœ€å°ç¼©æ”¾æ¯”ä¾‹
        zoom_max: æœ€å¤§ç¼©æ”¾æ¯”ä¾‹
        zoom_duration: æ¯æ¬¡ç¼©æ”¾çš„æŒç»­æ—¶é—´(ç§’)

    Returns:
        è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    from moviepy import VideoFileClip

    try:
        print("ğŸ¬ æ­£åœ¨åº”ç”¨è¿é•œæ•ˆæœ...")

        video = VideoFileClip(video_path)
        w, h = video.size

        # ä¸ºæ¯ä¸ªèŠ‚æ‹åˆ›å»ºç¼©æ”¾å…³é”®å¸§
        # ä½¿ç”¨ç®€å•çš„ç¼©æ”¾ç­–ç•¥: åœ¨èŠ‚æ‹å¤„æ”¾å¤§,ç„¶åç¼©å°
        def zoom_effect(get_frame, t):
            # æ‰¾åˆ°æœ€è¿‘çš„èŠ‚æ‹
            if not beat_times:
                return get_frame(t)

            # æ‰¾åˆ°æœ€è¿‘çš„èŠ‚æ‹æ—¶é—´
            beat_deltas = [abs(t - beat) for beat in beat_times]
            nearest_beat_dist = min(beat_deltas)

            # å¦‚æœæ¥è¿‘èŠ‚æ‹,åº”ç”¨ç¼©æ”¾
            if nearest_beat_dist < zoom_duration:
                # è®¡ç®—ç¼©æ”¾å› å­: èŠ‚æ‹å¤„æœ€å¤§,ç„¶åè¡°å‡
                progress = nearest_beat_dist / zoom_duration
                zoom_factor = zoom_max - (zoom_max - zoom_min) * progress
            else:
                zoom_factor = zoom_min

            # åº”ç”¨ç¼©æ”¾
            frame = get_frame(t)
            # è®¡ç®—ç¼©æ”¾åçš„å°ºå¯¸
            new_w, new_h = int(w / zoom_factor), int(h / zoom_factor)

            # å±…ä¸­è£å‰ª
            x1 = (w - new_w) // 2
            y1 = (h - new_h) // 2
            x2 = x1 + new_w
            y2 = y1 + new_h

            # è£å‰ªå¹¶ç¼©æ”¾å›åŸå°ºå¯¸
            from cv2 import resize
            cropped = frame[y1:y2, x1:x2]
            if cropped.size == 0:
                return frame
            return resize(cropped, (w, h))

        # åº”ç”¨æ•ˆæœ
        result = video.fl(zoom_effect)

        print(f"âœ… è¿é•œæ•ˆæœå·²åº”ç”¨")
        return result

    except Exception as e:
        print(f"âŒ åº”ç”¨æ•ˆæœå¤±è´¥: {e}")
        return None


def process_video(video_path: str, output_path: str,
                  sensitivity: float = 0.5,
                  zoom_min: float = 1.0,
                  zoom_max: float = 1.3,
                  zoom_duration: float = 0.2) -> bool:
    """
    å¤„ç†è§†é¢‘çš„ä¸»å‡½æ•°

    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        sensitivity: èŠ‚æ‹æ£€æµ‹çµæ•åº¦ (0.0-1.0)
        zoom_min: æœ€å°ç¼©æ”¾æ¯”ä¾‹
        zoom_max: æœ€å¤§ç¼©æ”¾æ¯”ä¾‹
        zoom_duration: ç¼©æ”¾æŒç»­æ—¶é—´(ç§’)

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    from moviepy import VideoFileClip

    # éªŒè¯è¾“å…¥
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return False

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as tmpdir:
        audio_path = os.path.join(tmpdir, "audio.wav")

        # æ­¥éª¤1: æå–éŸ³é¢‘
        if not extract_audio(video_path, audio_path):
            return False

        # æ­¥éª¤2: æ£€æµ‹èŠ‚æ‹
        beat_times, duration = detect_beats(audio_path, sensitivity)
        if not beat_times:
            print("âŒ æœªæ£€æµ‹åˆ°èŠ‚æ‹")
            return False

        # æ­¥éª¤3: åº”ç”¨ç¼©æ”¾æ•ˆæœ
        try:
            print("ğŸ¬ æ­£åœ¨æ¸²æŸ“æœ€ç»ˆè§†é¢‘...")

            video = VideoFileClip(video_path)
            original_audio = video.audio
            w, h = video.size
            fps = video.fps

            # ä½¿ç”¨ cv2 è¿›è¡Œæ›´é«˜æ•ˆçš„å¤„ç†
            try:
                import cv2
            except ImportError:
                print("âŒ éœ€è¦å®‰è£… cv2 (opencv-python)")
                print("  pip install opencv-python")
                return False

            # åˆ›å»ºä¸´æ—¶æ— éŸ³é¢‘è§†é¢‘æ–‡ä»¶
            temp_video_no_audio = os.path.join(tmpdir, "temp_no_audio.mp4")

            # ä½¿ç”¨ H.264 ç¼–ç å™¨è·å¾—æ›´å¥½çš„è´¨é‡
            fourcc = cv2.VideoWriter_fourcc(*'avc1')
            out = cv2.VideoWriter(temp_video_no_audio, fourcc, fps, (w, h))

            # é€å¸§å¤„ç†
            total_frames = int(duration * fps)
            for i in range(total_frames):
                t = i / fps

                # è·å–åŸå§‹å¸§
                frame = video.get_frame(t)

                # è®¡ç®—ç¼©æ”¾å› å­
                if beat_times:
                    beat_deltas = [abs(t - beat) for beat in beat_times]
                    nearest_beat_dist = min(beat_deltas)

                    if nearest_beat_dist < zoom_duration:
                        progress = nearest_beat_dist / zoom_duration
                        zoom_factor = zoom_max - (zoom_max - zoom_min) * progress
                    else:
                        zoom_factor = zoom_min
                else:
                    zoom_factor = zoom_min

                # åº”ç”¨ç¼©æ”¾
                if zoom_factor > zoom_min:
                    new_w, new_h = int(w / zoom_factor), int(h / zoom_factor)
                    x1 = (w - new_w) // 2
                    y1 = (h - new_h) // 2
                    x2 = x1 + new_w
                    y2 = y1 + new_h

                    # OpenCV ä½¿ç”¨ BGR æ ¼å¼
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    cropped = frame_bgr[y1:y2, x1:x2]
                    # ä½¿ç”¨ LANCZOS æ’å€¼è·å¾—æ›´å¥½çš„ç¼©æ”¾è´¨é‡
                    frame = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)
                else:
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

                out.write(frame)

                # æ˜¾ç¤ºè¿›åº¦
                if i % 30 == 0:
                    print(f"   è¿›åº¦: {i/total_frames*100:.1f}%")

            out.release()

            # å¦‚æœæœ‰éŸ³é¢‘ï¼Œå…ˆä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_audio_path = None
            if original_audio is not None:
                print("ğŸ”Š æ­£åœ¨ä¿å­˜éŸ³é¢‘...")
                temp_audio_path = os.path.join(tmpdir, "temp_audio.wav")
                original_audio.write_audiofile(temp_audio_path)
                # å…³é—­åŸå§‹éŸ³é¢‘å’Œè§†é¢‘ä»¥é‡Šæ”¾èµ„æº
                original_audio.close()
                original_audio = None
            video.close()

            # æ·»åŠ éŸ³é¢‘åˆ°è§†é¢‘
            print("ğŸ”Š æ­£åœ¨åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘...")
            video_processed = VideoFileClip(temp_video_no_audio)

            if temp_audio_path is not None:
                from moviepy import AudioFileClip
                audio_final = AudioFileClip(temp_audio_path)
                final_video = video_processed.with_audio(audio_final)
            else:
                final_video = video_processed

            # ä½¿ç”¨é«˜æ¯”ç‰¹ç‡è¾“å‡ºä»¥ä¿è¯è´¨é‡
            final_video.write_videofile(
                output_path,
                codec='libx264',
                audio_codec='aac',
                bitrate='8000k'  # é«˜æ¯”ç‰¹ç‡ä¿è¯è´¨é‡
            )

            video_processed.close()
            final_video.close()

            print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
            return True

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    parser = argparse.ArgumentParser(
        description='ä¸ºèˆè¹ˆè§†é¢‘æ·»åŠ è·ŸéšéŸ³ä¹èŠ‚å¥çš„ç¼©æ”¾è¿é•œæ•ˆæœ'
    )
    parser.add_argument('video', help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºè§†é¢‘è·¯å¾„ (é»˜è®¤: output_rhythm.mp4)')
    parser.add_argument('-s', '--sensitivity', type=float, default=0.5,
                       help='èŠ‚æ‹æ£€æµ‹çµæ•åº¦ (0.0-1.0, é»˜è®¤: 0.5)')
    parser.add_argument('--zoom-min', type=float, default=1.0,
                       help='æœ€å°ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤: 1.0)')
    parser.add_argument('--zoom-max', type=float, default=1.3,
                       help='æœ€å¤§ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤: 1.3)')
    parser.add_argument('--zoom-duration', type=float, default=0.2,
                       help='ç¼©æ”¾æŒç»­æ—¶é—´(ç§’) (é»˜è®¤: 0.2)')

    args = parser.parse_args()

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if args.output:
        output_path = args.output
    else:
        base, _ = os.path.splitext(args.video)
        output_path = f"{base}_rhythm.mp4"

    # å¤„ç†è§†é¢‘
    success = process_video(
        args.video,
        output_path,
        sensitivity=args.sensitivity,
        zoom_min=args.zoom_min,
        zoom_max=args.zoom_max,
        zoom_duration=args.zoom_duration
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
